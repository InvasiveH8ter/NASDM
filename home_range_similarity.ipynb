{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f6c77f-395e-4e73-8ecd-e151894b737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***You need to run this GEE script for your state and homerange first***\n",
    "# https://code.earthengine.google.com/b5d49bb675cc2d6583e866dc1dfb440b\n",
    "#get taxon key for your AIS from gbif\n",
    "#species.name_backbone(name='Dreissena polymorpha', kingdom='animal')\n",
    "my_training_state = 'MN' # should be the postal code abbreviation for the state you created the environmental raster for....\n",
    "my_nas_id = 5 # go to USGS NAS database for species_ids (e.g., 5 = Zebra Mussels; 237 = Eurasian watermilfoil; 551 = Bighead carp)\n",
    "my_path = 'data/' + my_training_state + '/'\n",
    "homerange_raster = my_path + \"homerange_2003_2022.tif\"\n",
    "invaded_raster = my_path + \"inv_rsd_2003_2022.tif\"\n",
    "my_countries = [\"RU\", \"UA\", \"BG\", \"RO\", \"GE\", \"AZ\", \"TM\", \"KZ\"] # Endemic range countries for your taxa\n",
    "my_taxon = 2287072  # gbif taxon id ; Eurasian watermilfoil = 2362486; Zebra mussels = 2362486\n",
    "limit = 10000 # This is for the gbif function so you don't blow up your computer... Just kidding that shouldn't happen : )\n",
    "my_scale = 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7b95b9-72b2-4248-843d-127748453486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import requests\n",
    "import glob\n",
    "from pygbif import occurrences as occ \n",
    "from pygbif import species\n",
    "import rasterio\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Functions\n",
    "def gbif_api_call(taxon, country, limit):\n",
    "    \"\"\"Fetch GBIF occurrences for a given taxon and country.\"\"\"\n",
    "    URL_BASE = 'https://api.gbif.org/v1/'\n",
    "    url_request = f\"{URL_BASE}occurrence/search?taxonKey={taxon}&country={country}&limit={limit}\"  \n",
    "    response = requests.get(url_request, timeout=30)\n",
    "    return response.json()  # Return the JSON response directly\n",
    "\n",
    "def nas_api_call(nas_id, state):\n",
    "    URL_BASE = 'http://nas.er.usgs.gov/api/v2/'\n",
    "    url_request = f\"{URL_BASE}/occurrence/search?species_ID={nas_id}&state={my_training_state}\"\n",
    "    response = requests.get(url_request, timeout=None).json()\n",
    "    results = pd.json_normalize(response, 'results')\n",
    "    return results\n",
    "\n",
    "\n",
    "def sample_multiband_geotiff_with_names(raster_path, gdf):\n",
    "    \"\"\"\n",
    "    Samples a multi-band GeoTIFF at specified point locations from a GeoDataFrame,\n",
    "    using band names from the raster.\n",
    "\n",
    "    Parameters:\n",
    "    - raster_path (str): Path to the GeoTIFF file.\n",
    "    - gdf (GeoDataFrame): GeoDataFrame containing point geometries.\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame with additional columns for each band, using raster band names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the raster file\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Reproject GeoDataFrame to match raster CRS if needed\n",
    "        if gdf.crs != src.crs:\n",
    "            gdf = gdf.to_crs(src.crs)\n",
    "\n",
    "        # Convert point geometries to raster pixel coordinates\n",
    "        coords = [(geom.x, geom.y) for geom in gdf.geometry]\n",
    "\n",
    "        # Sample raster at point locations (returns a list of tuples with values per band)\n",
    "        sampled_values = list(src.sample(coords))\n",
    "\n",
    "        # Get band names (if available, otherwise use default names)\n",
    "        band_names = src.descriptions if all(src.descriptions) else [f\"band_{i+1}\" for i in range(src.count)]\n",
    "\n",
    "        # Create new columns in the GeoDataFrame with the corresponding band names\n",
    "        for band_idx, band_name in enumerate(band_names):\n",
    "            gdf[band_name] = [val[band_idx] for val in sampled_values]\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def filter_dataframe_columns(df, feature_choices):\n",
    "    return df[[col for col in df.columns if col in feature_choices or col == \"geometry\"]]\n",
    "\n",
    "def extract_fields(data):\n",
    "    \"\"\"Extract relevant fields from GBIF response.\"\"\"\n",
    "    extracted_data = []\n",
    "    for record in data:\n",
    "        entry = {\n",
    "            'key': record.get('key'),\n",
    "            'species': record.get('species'),\n",
    "            'decimalLatitude': record.get('decimalLatitude'),\n",
    "            'decimalLongitude': record.get('decimalLongitude'),\n",
    "            'countryCode': record.get('countryCode'),\n",
    "            'year': record.get('year')\n",
    "        }\n",
    "        extracted_data.append(entry)\n",
    "    return extracted_data\n",
    "\n",
    "def MESS(ref_df, pred_df):\n",
    "    # Extract geometry before dropping it\n",
    "    geometry = None\n",
    "    if \"geometry\" in pred_df.columns:\n",
    "        geometry = pred_df[\"geometry\"].copy()  # Save geometry separately\n",
    "        pred_df = pred_df.drop(columns=[\"geometry\", \"predID\"])  # Drop before calculations\n",
    "\n",
    "    # Ensure reference DataFrame does not include geometry\n",
    "    ref_numeric = ref_df.drop(columns=[\"geometry\"], errors=\"ignore\")  # Avoid geometry errors\n",
    "\n",
    "    # Compute min and max values for each variable\n",
    "    mins = dict(ref_numeric.min())\n",
    "    maxs = dict(ref_numeric.max())\n",
    "\n",
    "    def calculate_s(column):\n",
    "        values = ref_numeric[column]  # Reference values\n",
    "        sims = []\n",
    "\n",
    "        for element in np.array(pred_df[column]):\n",
    "            f = np.count_nonzero((values < element)) / values.size\n",
    "\n",
    "            if f == 0:\n",
    "                sim = ((element - mins[column]) / (maxs[column] - mins[column]))\n",
    "            elif 0 < f <= 50:\n",
    "                sim = 2 * f\n",
    "            elif 50 < f < 100:\n",
    "                sim = 2 * (1 - f)\n",
    "            elif f == 100:\n",
    "                sim = ((maxs[column] - element) / (maxs[column] - mins[column]))\n",
    "\n",
    "            sims.append(sim)\n",
    "\n",
    "        return sims\n",
    "\n",
    "    # Compute similarity scores for each predictor\n",
    "    sim_df = pd.DataFrame()\n",
    "    for c in pred_df.columns:\n",
    "        sim_df[c] = calculate_s(c)\n",
    "\n",
    "    # Compute MESS values\n",
    "    min_similarity = sim_df.min(axis=1)  # Least similar predictor's score\n",
    "    MoD = sim_df.idxmin(axis=1)  # Least similar predictor's name\n",
    "\n",
    "    # Combine results\n",
    "    MESS = pd.concat([min_similarity, MoD], axis=1)\n",
    "    MESS.columns = [\"MESS_Score\", \"Least_Similar_Variable\"]\n",
    "\n",
    "    # Reattach geometry if it was present\n",
    "    if geometry is not None:\n",
    "        print(\"Before reattaching geometry:\", MESS.dtypes)  # Debug print\n",
    "    \n",
    "        MESS[\"geometry\"] = geometry  # Re-add geometry\n",
    "        MESS = gpd.GeoDataFrame(MESS, geometry=\"geometry\", crs=5070)  # Convert back to GeoDataFrame\n",
    "        \n",
    "        print(\"After reattaching geometry:\", MESS.dtypes)  # Debug print\n",
    "        print(\"Geometry column exists?\", \"geometry\" in MESS.columns)\n",
    "    \n",
    "    return MESS\n",
    "\n",
    "def export_mess(joined_gdf: gpd.GeoDataFrame, resolution: int = my_scale):\n",
    "    # Ensure CRS is projected (use EPSG:5070 or appropriate for your region)\n",
    "    if joined_gdf.crs.to_epsg() != 5070:\n",
    "        joined_gdf = joined_gdf.to_crs(epsg=5070)\n",
    "\n",
    "    # Get bounds\n",
    "    bounds = joined_gdf.total_bounds  # [minx, miny, maxx, maxy]\n",
    "    print(f\"Bounds in projected CRS: {bounds}\")\n",
    "\n",
    "    # Compute raster size\n",
    "    width = int(np.ceil((bounds[2] - bounds[0]) / resolution))\n",
    "    height = int(np.ceil((bounds[3] - bounds[1]) / resolution))\n",
    "\n",
    "    if width <= 0 or height <= 0:\n",
    "        raise ValueError(f\"Invalid raster dimensions: width={width}, height={height}\")\n",
    "\n",
    "    # Define transform\n",
    "    transform = rasterio.transform.from_origin(bounds[0], bounds[3], resolution, resolution)\n",
    "\n",
    "    # Ensure \"mess\" column exists and is numeric\n",
    "    column_name = \"MESS_Score\"\n",
    "    if column_name not in joined_gdf.columns:\n",
    "        raise KeyError(f\"Column '{column_name}' is missing from the GeoDataFrame!\")\n",
    "\n",
    "    joined_gdf[column_name] = joined_gdf[column_name].fillna(0).astype(float)\n",
    "\n",
    "    # Prepare shapes for rasterization\n",
    "    shapes = [(geom, value) for geom, value in zip(joined_gdf.geometry, joined_gdf[column_name]) if not np.isnan(value)]\n",
    "\n",
    "    # Create raster\n",
    "    raster = rasterize(\n",
    "        shapes=shapes,\n",
    "        out_shape=(height, width),\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n",
    "    # Save to file\n",
    "    output_filename = f\"{my_path}{my_training_state}_{column_name}.tif\"\n",
    "    with rasterio.open(\n",
    "        output_filename, \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,\n",
    "        dtype=rasterio.float32,\n",
    "        crs=joined_gdf.crs,  # Use the same projected CRS\n",
    "        transform=transform\n",
    "    ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "        dst.set_band_description(1, column_name)\n",
    "\n",
    "    # Check raster output\n",
    "    #print(f\"Raster saved as: {output_filename}\")\n",
    "    #print(f\"Unique raster values: {np.unique(raster)}\")  # Ensure non-zero values exist\n",
    "\n",
    "    # Plot the raster\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(raster, cmap=\"viridis\", extent=[bounds[0], bounds[2], bounds[1], bounds[3]])\n",
    "    plt.colorbar(label=f'{column_name}')\n",
    "    plt.title('Rasterized MESS')\n",
    "    plt.xlabel('X (meters)')\n",
    "    plt.ylabel('Y (meters)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc5d0d3-c517-421b-b28b-d6d461151f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbif_result = []\n",
    "for country in my_countries:\n",
    "    result = gbif_api_call(my_taxon, country, limit)\n",
    "    gbif_result.extend(result.get(\"results\", []))  # Append results directly\n",
    "# Extract fields from all collected results\n",
    "homerange_points = pd.DataFrame(extract_fields(gbif_result))\n",
    "homerange_points = gpd.GeoDataFrame(\n",
    "    homerange_points, geometry=gpd.points_from_xy(homerange_points.decimalLongitude, homerange_points.decimalLatitude)).dropna().set_crs(4269).to_crs(5070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07a028a-e18e-426a-954d-275b0672d7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Band Names: ['NDTI', 'NDBI', 'NDCI', 'NDVI', 'GPP_Annual', 'GPP_Summer', 'Precip_Winter', 'Precip_Spring', 'Precip_Summer', 'Precip_Fall', 'Heat_Insolation', 'Topo_Diversity', 'gHM', 'NDSI', 'Flashiness', 'Runoff', 'Drawdown', 'LST_Annual', 'LST_Summer', 'LST_Winter', 'LST_Spring', 'LST_Fall']\n"
     ]
    }
   ],
   "source": [
    "# Load raster dataset (assume multiband raster where each band is a predictor)\n",
    "raster_path = invaded_raster\n",
    "with rasterio.open(raster_path) as src:\n",
    "    out_image = src.read()  # Read all bands without masking\n",
    "    meta = src.meta  # Store metadata for later use\n",
    "    transform = src.transform  # Affine transform for georeferencing\n",
    "\n",
    "    # Extract band names or fallback to generic names\n",
    "    band_names = [src.descriptions[i] if src.descriptions and src.descriptions[i] else f\"Band_{i+1}\" \n",
    "                  for i in range(src.count)]\n",
    "    print(\"Extracted Band Names:\", band_names)  # Debugging step\n",
    "\n",
    "# Convert extracted raster data to a DataFrame\n",
    "bands, height, width = out_image.shape\n",
    "pixels = out_image.reshape(bands, -1).T  # Flatten to (num_pixels, num_bands)\n",
    "pred_data = pd.DataFrame(pixels, columns=band_names)\n",
    "\n",
    "# Handle NoData values (if applicable)\n",
    "if meta.get(\"nodata\") is not None:\n",
    "    pred_data.replace(meta[\"nodata\"], np.nan, inplace=True)\n",
    "\n",
    "# Generate coordinates for each pixel\n",
    "row_indices, col_indices = np.indices((height, width))\n",
    "x_coords, y_coords = rasterio.transform.xy(transform, row_indices.flatten(), col_indices.flatten())\n",
    "\n",
    "# Create geometries (Point objects)\n",
    "geometries = [Point(x, y) for x, y in zip(x_coords, y_coords)]\n",
    "\n",
    "# Convert DataFrame to GeoDataFrame\n",
    "my_pred_data = gpd.GeoDataFrame(pred_data, geometry=geometries, crs=5070).reset_index().rename(columns ={'index':'predID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618745ce-665e-4934-ba37-9edd9ba12d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_choices = ['NDBI', 'NDTI', 'NDSI', 'NDCI', 'GPP_Summer', 'gHM', \n",
    "            'Heat_Insolation', 'Topo_Diversity', 'Flashiness', 'LST_Summer',\n",
    "            'LST_Winter','NDVI','LST_Spring','LST_Fall', 'Precip_Winter', \n",
    "            'Precip_Spring', 'Precip_Summer', 'Precip_Fall', 'Drawdown', 'Runoff', 'geometry', 'predID']\n",
    "ref_data = sample_multiband_geotiff_with_names(homerange_raster, homerange_points)\n",
    "my_ref_data = filter_dataframe_columns(ref_data, feature_choices).dropna()\n",
    "my_pred_data = filter_dataframe_columns(my_pred_data, feature_choices).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe123e8-f3ee-4220-99c5-80f55007d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mess = MESS(my_ref_data, my_pred_data)\n",
    "my_mess_clean = my_mess.dropna()\n",
    "export_mess(my_mess_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68586e74-899c-423f-8956-fcc5f2c945ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f92461-f54f-4edc-8cfc-ed2bb61c79a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb28a97-b9e6-4780-b5fc-b61be72e8869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
