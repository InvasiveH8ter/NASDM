{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6fc8aa-ef87-4edc-8a1e-e6a969f3e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.ops import nearest_points\n",
    "import networkx as nx\n",
    "from shapely.geometry import Point, LineString\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import io\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.ops import snap, nearest_points\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f4d492f-0e04-4a01-a8f8-e1d505b3af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nas_api_call(nas_id, state):\n",
    "    URL_BASE = 'http://nas.er.usgs.gov/api/v2/'\n",
    "    url_request = f\"{URL_BASE}/occurrence/search?species_ID={nas_id}&state={my_training_state}\"\n",
    "    response = requests.get(url_request, timeout=None).json()\n",
    "    results = pd.json_normalize(response, 'results')\n",
    "    return results\n",
    "\n",
    "# Function to extract vertices from each LineString/MultiLineString\n",
    "def extract_vertices(geometry):\n",
    "    if geometry.geom_type == \"LineString\":\n",
    "        return list(geometry.coords)  # Extract vertices from LineString\n",
    "    elif geometry.geom_type == \"MultiLineString\":\n",
    "        return [coord for line in geometry.geoms for coord in line.coords]  # Flatten MultiLineString\n",
    "    return []\n",
    "\n",
    "def snap_points_to_nearest_line(line: gpd.GeoDataFrame, point: gpd.GeoDataFrame, snapdist: float) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Snaps points to the nearest polygon within a given distance.\n",
    "    \n",
    "    Parameters:\n",
    "        poly (GeoDataFrame): GeoDataFrame containing polygon geometries.\n",
    "        point (GeoDataFrame): GeoDataFrame containing point geometries.\n",
    "        snapdist (float): Maximum search distance to find the nearest polygon.\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: Updated point GeoDataFrame with snapped geometries.\n",
    "    \"\"\"\n",
    "    # Ensure both datasets use the same projected CRS (Sweden EPSG:3006 in original, changed to 26915)\n",
    "    line = line.to_crs(4269)\n",
    "    point = point.set_crs(4269)\n",
    "    \n",
    "    # Create unique IDs\n",
    "    line[\"lineid\"] = range(line.shape[0])\n",
    "    point[\"pointid\"] = range(point.shape[0])\n",
    "    \n",
    "    # Store original polygon geometry\n",
    "    line[\"linegeom\"] = line.geometry\n",
    "    \n",
    "    # Perform spatial join to find nearest polygons within snap distance\n",
    "    sj = gpd.sjoin_nearest(left_df=point, right_df=line, how=\"left\", max_distance=snapdist)\n",
    "    \n",
    "    # Measure distances (set to None if no polygon within snapdistance)\n",
    "    sj[\"distance\"] = sj.apply(lambda x: x.geometry.distance(x.linegeom) if x.linegeom is not None else None, axis=1)\n",
    "    \n",
    "    # Sort by distance and drop duplicates (keeping closest polygon match)\n",
    "    sj = sj.sort_values(by=[\"pointid\", \"distance\"], ascending=True, na_position=\"last\")\n",
    "    sj = sj.drop_duplicates(subset=\"pointid\", keep=\"first\")\n",
    "    \n",
    "    # Find the nearest point on the polygon\n",
    "    sj[\"nearestpoint\"] = sj.apply(\n",
    "        lambda x: nearest_points(x.geometry, x.linegeom)[1] if (x.linegeom is not None and x.distance is not None) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Snap points to nearest point on polygon if applicable\n",
    "    sj[\"geometry\"] = sj.apply(\n",
    "        lambda x: snap(x.geometry, x.nearestpoint, snapdist) if x.nearestpoint is not None else x.geometry,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return sj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc139b57-8b8d-4e56-a8ca-4552863cb9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "my_training_state = 'MN' # State USPS abbreviation\n",
    "state_name = 'Minnesota'\n",
    "my_nas_id = 5\n",
    "# IA = 19; ID = 16; IL = 17; MN = 27; MO = 29; MT = 30; OR = 41;  WA = 53; WI = 55\n",
    "state_fips = '27' # Replace last 2 digits with your state's FIP code\n",
    "my_path = 'data/' + my_training_state + '/' # leave this alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4a0bb1c-886d-449e-9b40-89a31b8634a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NAS data\n",
    "pos_data = nas_api_call(my_nas_id, my_training_state)\n",
    "my_data = pos_data[[\"decimalLatitude\", \"decimalLongitude\"]]\n",
    "pos_data_gdf = gpd.GeoDataFrame(\n",
    "    my_data, geometry=gpd.points_from_xy(my_data.decimalLongitude, my_data.decimalLatitude)).dropna().set_crs(4269)#.to_crs(5070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12776de4-1fab-4582-b894-9ad565d313b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully merged shapefiles into a single GeoDataFrame.\n",
      "Imported 1 shapefiles\n"
     ]
    }
   ],
   "source": [
    "# Import flowline\n",
    "# Import stream files\n",
    "# Find all shapefiles that include \"NHDFlowline_\" in the filename\n",
    "shapefiles = glob.glob(os.path.join(my_path + \"/shape/\", \"*NHDFlowline_*.shp\")) + glob.glob(os.path.join(my_path + \"/shape/\", \"NHDFlowline.shp\"))\n",
    "\n",
    "# Ensure shapefiles were found\n",
    "if not shapefiles:\n",
    "    print(\"No shapefiles found matching the pattern.\")\n",
    "\n",
    "# Load all shapefiles into a list of GeoDataFrames\n",
    "gdfs = [gpd.read_file(shp) for shp in shapefiles]\n",
    "\n",
    "# Optionally, concatenate all shapefiles into a single GeoDataFrame\n",
    "if gdfs:  # Only concatenate if the list is not empty\n",
    "    stream_gdf = gpd.pd.concat(gdfs, ignore_index=True)\n",
    "    print(\"Successfully merged shapefiles into a single GeoDataFrame.\")\n",
    "else:\n",
    "    stream_gdf = None\n",
    "    print(\"No valid shapefiles to merge.\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"Imported {len(gdfs)} shapefiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "582ce3a0-3a8c-4de4-b250-e13baf2b0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to extract vertices\n",
    "stream_gdf[\"vertices\"] = stream_gdf[\"geometry\"].apply(extract_vertices)\n",
    "\n",
    "# Convert to DataFrame with separate rows for each vertex\n",
    "vertices_gdf = stream_gdf.explode(\"vertices\", ignore_index=True)\n",
    "\n",
    "# Convert extracted coordinates to Point geometries\n",
    "vertices_gdf[\"geometry\"] = vertices_gdf[\"vertices\"].apply(lambda v: Point(v))\n",
    "\n",
    "# Drop the original tuple column\n",
    "vertices_gdf.drop(columns=[\"vertices\"], inplace=True)\n",
    "\n",
    "# Ensure the final output remains a GeoDataFrame with the correct CRS\n",
    "vertices_gdf = gpd.GeoDataFrame(vertices_gdf, geometry=\"geometry\", crs=stream_gdf.crs)\n",
    "\n",
    "duplicate_mask = vertices_gdf.duplicated(subset=[\"geometry\"], keep=False)\n",
    "# Get only the duplicate geometries\n",
    "my_vertices = vertices_gdf[duplicate_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7224633-8688-483d-bb47-22d3cf1ba72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vertices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbedc151-6d08-445f-8721-520fb2a50b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leif.howard\\AppData\\Local\\anaconda3\\envs\\masters\\Lib\\site-packages\\geopandas\\array.py:365: UserWarning: Geometry is in a geographic CRS. Results from 'sjoin_nearest' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Snap occurences to lines \n",
    "snapped_occ = snap_points_to_nearest_line(stream_gdf, pos_data_gdf,  10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b185e-ba9b-4aa0-a23b-a2e835ff189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot each dataset with a different style\n",
    "stream_gdf.plot(ax=ax, color=\"blue\", linewidth=1, label=\"Streams\")  # Line features\n",
    "my_vertices.plot(ax=ax, color=\"red\", markersize=10, label=\"Vertices\")  # Points\n",
    "snapped_occ.plot(ax=ax, color=\"green\", markersize=20, marker=\"*\", label=\"Snapped Occ\")  # Highlighted points\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9f20236-37b1-4080-a89e-b5e78f308f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leif.howard\\AppData\\Local\\anaconda3\\envs\\masters\\Lib\\site-packages\\geopandas\\array.py:365: UserWarning: Geometry is in a geographic CRS. Results from 'sjoin_nearest' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "joined = gpd.sjoin_nearest(my_vertices, snapped_occ.drop(columns=[\"index_right\"], errors=\"ignore\"), how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99c801da-44a2-4638-95ad-056ef5ad362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 683491 entries, 0 to 14019335\n",
      "Data columns (total 42 columns):\n",
      " #   Column            Non-Null Count   Dtype   \n",
      "---  ------            --------------   -----   \n",
      " 0   permanent__left   683491 non-null  object  \n",
      " 1   fdate_left        683491 non-null  object  \n",
      " 2   resolution_left   683491 non-null  int64   \n",
      " 3   gnis_id_left      155659 non-null  object  \n",
      " 4   gnis_name_left    155659 non-null  object  \n",
      " 5   lengthkm_left     683491 non-null  float64 \n",
      " 6   reachcode_left    683491 non-null  object  \n",
      " 7   flowdir_left      683491 non-null  int64   \n",
      " 8   wbarea_per_left   219153 non-null  object  \n",
      " 9   ftype_left        683491 non-null  int64   \n",
      " 10  fcode_left        683491 non-null  int64   \n",
      " 11  mainpath_left     683491 non-null  int64   \n",
      " 12  innetwork_left    683491 non-null  int64   \n",
      " 13  visibility_left   683491 non-null  int64   \n",
      " 14  SHAPE_Leng_left   0 non-null       object  \n",
      " 15  ObjectID_left     683491 non-null  int64   \n",
      " 16  geometry          683491 non-null  geometry\n",
      " 17  index_right       683491 non-null  int64   \n",
      " 18  decimalLatitude   683491 non-null  float64 \n",
      " 19  decimalLongitude  683491 non-null  float64 \n",
      " 20  pointid           683491 non-null  int64   \n",
      " 21  permanent__right  683491 non-null  object  \n",
      " 22  fdate_right       683491 non-null  object  \n",
      " 23  resolution_right  683491 non-null  int64   \n",
      " 24  gnis_id_right     229348 non-null  object  \n",
      " 25  gnis_name_right   229348 non-null  object  \n",
      " 26  lengthkm_right    683491 non-null  float64 \n",
      " 27  reachcode_right   683491 non-null  object  \n",
      " 28  flowdir_right     683491 non-null  int64   \n",
      " 29  wbarea_per_right  559661 non-null  object  \n",
      " 30  ftype_right       683491 non-null  int64   \n",
      " 31  fcode_right       683491 non-null  int64   \n",
      " 32  mainpath_right    683491 non-null  int64   \n",
      " 33  innetwork_right   683491 non-null  int64   \n",
      " 34  visibility_right  683491 non-null  int64   \n",
      " 35  SHAPE_Leng_right  0 non-null       object  \n",
      " 36  ObjectID_right    683491 non-null  int64   \n",
      " 37  vertices          683491 non-null  object  \n",
      " 38  lineid            683491 non-null  int64   \n",
      " 39  linegeom          683491 non-null  geometry\n",
      " 40  distance          683491 non-null  float64 \n",
      " 41  nearestpoint      683491 non-null  geometry\n",
      "dtypes: float64(5), geometry(3), int64(19), object(15)\n",
      "memory usage: 224.2+ MB\n"
     ]
    }
   ],
   "source": [
    "joined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c2dee-08ab-4863-8ec8-0d528c893699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefiles\n",
    "source_gdf = my_vertices.to_crs(3857)\n",
    "target_gdf = snapped_occ.to_crs(3857)\n",
    "network_gdf = stream_gdf.to_crs(3857)\n",
    "\n",
    "# Ensure all GeoDataFrames use the same CRS\n",
    "if not (source_gdf.crs == target_gdf.crs == network_gdf.crs):\n",
    "    target_gdf = target_gdf.to_crs(source_gdf.crs)\n",
    "    network_gdf = network_gdf.to_crs(source_gdf.crs)\n",
    "\n",
    "# Build a graph from the polyline network\n",
    "def build_network(gdf):\n",
    "    G = nx.Graph()\n",
    "    for _, row in gdf.iterrows():\n",
    "        line = row.geometry\n",
    "        if isinstance(line, LineString):\n",
    "            coords = list(line.coords)\n",
    "            for i in range(len(coords) - 1):\n",
    "                G.add_edge(\n",
    "                    coords[i],\n",
    "                    coords[i + 1],\n",
    "                    weight=Point(coords[i]).distance(Point(coords[i + 1]))\n",
    "                )\n",
    "    return G\n",
    "\n",
    "network_graph = build_network(network_gdf)\n",
    "\n",
    "# Snap a point to the nearest point on the network\n",
    "def snap_point_to_network(point, network_gdf, graph):\n",
    "    nearest_line = network_gdf.loc[network_gdf.distance(point).idxmin()]\n",
    "    snapped_point = nearest_points(point, nearest_line.geometry)[1]\n",
    "    snapped_coords = (snapped_point.x, snapped_point.y)\n",
    "    \n",
    "    coords = list(nearest_line.geometry.coords)\n",
    "    for i in range(len(coords) - 1):\n",
    "        start, end = coords[i], coords[i + 1]\n",
    "        segment = LineString([start, end])\n",
    "        if segment.distance(snapped_point) < 1e-6:\n",
    "            graph.add_edge(start, snapped_coords, weight=Point(start).distance(snapped_point))\n",
    "            graph.add_edge(snapped_coords, start, weight=Point(start).distance(snapped_point))\n",
    "            graph.add_edge(end, snapped_coords, weight=Point(end).distance(snapped_point))\n",
    "            graph.add_edge(snapped_coords, end, weight=Point(end).distance(snapped_point))\n",
    "            break\n",
    "    return snapped_coords\n",
    "\n",
    "# Identify connected and disconnected point pairs\n",
    "def identify_connected_disconnected_pairs(point_pairs, source_gdf, target_gdf, network_gdf, network_graph):\n",
    "    connected_pairs = []\n",
    "    disconnected_pairs = []\n",
    "    \n",
    "    for pair in point_pairs:\n",
    "        source_id, target_id = pair\n",
    "        \n",
    "        source_geom = source_gdf[source_gdf[\"ObjectID\"] == source_id].iloc[0].geometry\n",
    "        target_geom = target_gdf[target_gdf[\"ObjectID\"] == target_id].iloc[0].geometry\n",
    "        \n",
    "        source_node = snap_point_to_network(source_geom, network_gdf, network_graph)\n",
    "        target_node = snap_point_to_network(target_geom, network_gdf, network_graph)\n",
    "        \n",
    "        if nx.has_path(network_graph, source_node, target_node):\n",
    "            connected_pairs.append((pair, source_node, target_node))\n",
    "        else:\n",
    "            disconnected_pairs.append(pair)\n",
    "    \n",
    "    return connected_pairs, disconnected_pairs\n",
    "\n",
    "# Load point pairs\n",
    "point_pairs = joined[['ObjectID_left', 'ObjectID_right']].to_numpy()\n",
    "#point_pairs = point_pairs[:5]\n",
    "# Separate point pairs into connected and disconnected\n",
    "connected_pairs, disconnected_pairs = identify_connected_disconnected_pairs(\n",
    "    point_pairs, source_gdf, target_gdf, network_gdf, network_graph\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0bd5772-4484-4491-aaa3-5fef1ca04fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source_point_id  target_point_id  network_distance\n",
      "0                1           152949      82402.308297\n",
      "1                1           152949      82402.308297\n",
      "2                2           220601      39474.120888\n",
      "3                2           220601      39474.120888\n",
      "4                3             7944       9863.589331\n"
     ]
    }
   ],
   "source": [
    "# Calculate shortest distances for connected point pairs\n",
    "def calculate_shortest_distances(connected_pairs, network_graph):\n",
    "    results = []\n",
    "    for pair, source_node, target_node in connected_pairs:\n",
    "        source_id, target_id = pair\n",
    "        \n",
    "        path_length = nx.shortest_path_length(\n",
    "            network_graph, source_node, target_node, weight=\"weight\"\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            \"source_point_id\": source_id,\n",
    "            \"target_point_id\": target_id,\n",
    "            \"network_distance\": path_length\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Add disconnected pairs with \"inf\" distances\n",
    "def add_disconnected_pairs_to_results(disconnected_pairs):\n",
    "    return [\n",
    "        {\"source_point_id\": pair[0], \"target_point_id\": pair[1], \"network_distance\": float(\"inf\")}\n",
    "        for pair in disconnected_pairs\n",
    "    ]\n",
    "\n",
    "# Step 1: Calculate shortest distances for connected pairs\n",
    "connected_distances = calculate_shortest_distances(connected_pairs, network_graph)\n",
    "\n",
    "# Step 2: Add disconnected pairs\n",
    "disconnected_distances = add_disconnected_pairs_to_results(disconnected_pairs)\n",
    "\n",
    "# Step 3: Combine results\n",
    "all_distances = connected_distances + disconnected_distances\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(all_distances)\n",
    "\n",
    "# Print or save the results\n",
    "print(results_df)\n",
    "# results_df.to_csv(\"carp_distances.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2c8c1-7b87-460a-8476-bdd5ec7b7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"carp_distances.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a98c73-21bc-4c6d-ad20-f3d61875ef58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb7e65f-b997-4dbb-9ef0-80a95ba52332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80f0d8-bb70-4643-8eff-038dfb868819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt_pairs_gpd = gpd.read_file(\"point_pairs_to_filter.shp\")\n",
    "# shortest_pt_pairs = pt_pairs_gpd.loc[pt_pairs_gpd.groupby(\"sourceID\")[\"distance\"].idxmin()]\n",
    "# shortest_pt_pairs.to_file('point_pairs_filtered.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22db94e-158d-4dad-98be-da85d12241c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt_pairs_w_lakeID = gpd.read_file(\"pairs_w_LakeID_to_filter.shp\")\n",
    "# lake_pt_pairs = shortest_pt_pairs.loc[shortest_pt_pairs.groupby(\"lakeID\")[\"distance\"].idxmin()]\n",
    "# distance_removed = lake_pt_pairs.drop(columns = 'distance')\n",
    "# distance_removed.to_file('pairs_w_LakeID_filtered.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b404ef-2014-48d6-a7be-008068bc6776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
