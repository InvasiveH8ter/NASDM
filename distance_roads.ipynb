{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a035f18-d381-4e93-9c00-becab59a2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.ops import nearest_points\n",
    "import networkx as nx\n",
    "from shapely.geometry import Point, LineString\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import io\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.ops import snap, nearest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85b4480-9dc2-4218-93e6-4465aa4379ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "my_training_state = 'MN' # State USPS abbreviation\n",
    "state_name = 'Minnesota'\n",
    "my_nas_id = 5\n",
    "# IA = 19; ID = 16; IL = 17; MN = 27; MO = 29; MT = 30; OR = 41;  WA = 53; WI = 55\n",
    "state_fips = '27' # Replace last 2 digits with your state's FIP code\n",
    "my_path = 'data/' + my_training_state + '/' # leave this alone   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d38d9-e447-445c-ad43-247f4e4cde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download road shapefile\n",
    "road_url = f'https://www2.census.gov/geo/tiger/TIGER2022/PRISECROADS/tl_2022_{state_fips}_prisecroads.zip'\n",
    "local_path = my_path\n",
    "print('Downloading shapefile...')\n",
    "r = requests.get(road_url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "print(\"Done\")\n",
    "z.extractall(path=local_path) # extract to folder\n",
    "filenames = [y for y in sorted(z.namelist()) for ending in ['dbf', 'prj', 'shp', 'shx'] if y.endswith(ending)] \n",
    "print(filenames)\n",
    "#Download USGS boat access data \n",
    "# URL of the compressed file containing multiple files\n",
    "URL_BASE = \"https://www.sciencebase.gov/catalog/file/get/63b81b50d34e92aad3cc004d?facet=Boatramps_United_States_final_20230104\"\n",
    "\n",
    "# Define the desired extensions\n",
    "desired_extensions = ['.dbf', '.prj', '.shp', '.shx']\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(URL_BASE)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Save the content to a temporary location (e.g., in memory)\n",
    "    zip_file = BytesIO(response.content)\n",
    "\n",
    "    # Extract the ZIP file contents to a folder\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        # Create a directory to store the extracted files\n",
    "        os.makedirs(my_path, exist_ok=True)\n",
    "        \n",
    "        # Loop through the files in the zip and extract only the desired ones\n",
    "        for file_name in zip_ref.namelist():\n",
    "            if any(file_name.endswith(ext) for ext in desired_extensions):\n",
    "                # Extract the file\n",
    "                zip_ref.extract(file_name, my_path)\n",
    "                print(f\"Extracted: {file_name}\")\n",
    "\n",
    "    print(\"Files extracted successfully to my_path directory.\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86c1435-1326-4327-ab81-69ffe6664da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nas_api_call(nas_id, state):\n",
    "    URL_BASE = 'http://nas.er.usgs.gov/api/v2/'\n",
    "    url_request = f\"{URL_BASE}/occurrence/search?species_ID={nas_id}&state={my_training_state}\"\n",
    "    response = requests.get(url_request, timeout=None).json()\n",
    "    results = pd.json_normalize(response, 'results')\n",
    "    return results\n",
    "\n",
    "# Function to get the endpoints of a line geometry\n",
    "def get_endpoints(geometry):\n",
    "    # Ensure the geometry is a LineString\n",
    "    if geometry.geom_type == 'LineString':\n",
    "        # Get the first and last coordinate of the line\n",
    "        return [geometry.coords[0], geometry.coords[-1]]\n",
    "    return []\n",
    "\n",
    "def snap_points_to_nearest_poly(poly: gpd.GeoDataFrame, point: gpd.GeoDataFrame, snapdist: float) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Snaps points to the nearest polygon within a given distance.\n",
    "    \n",
    "    Parameters:\n",
    "        poly (GeoDataFrame): GeoDataFrame containing polygon geometries.\n",
    "        point (GeoDataFrame): GeoDataFrame containing point geometries.\n",
    "        snapdist (float): Maximum search distance to find the nearest polygon.\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: Updated point GeoDataFrame with snapped geometries.\n",
    "    \"\"\"\n",
    "    # Ensure both datasets use the same projected CRS (Sweden EPSG:3006 in original, changed to 26915)\n",
    "    poly = poly.to_crs(3857)\n",
    "    point = point.set_crs(3857)\n",
    "    \n",
    "    # Create unique IDs\n",
    "    poly[\"polyid\"] = range(poly.shape[0])\n",
    "    point[\"pointid\"] = range(point.shape[0])\n",
    "    \n",
    "    # Store original polygon geometry\n",
    "    poly[\"polygeom\"] = poly.geometry\n",
    "    \n",
    "    # Perform spatial join to find nearest polygons within snap distance\n",
    "    sj = gpd.sjoin_nearest(left_df=point, right_df=poly, how=\"left\", max_distance=snapdist)\n",
    "    \n",
    "    # Measure distances (set to None if no polygon within snapdistance)\n",
    "    sj[\"distance\"] = sj.apply(lambda x: x.geometry.distance(x.polygeom) if x.polygeom is not None else None, axis=1)\n",
    "    \n",
    "    # Sort by distance and drop duplicates (keeping closest polygon match)\n",
    "    sj = sj.sort_values(by=[\"pointid\", \"distance\"], ascending=True, na_position=\"last\")\n",
    "    sj = sj.drop_duplicates(subset=\"pointid\", keep=\"first\")\n",
    "    \n",
    "    # Find the nearest point on the polygon\n",
    "    sj[\"nearestpoint\"] = sj.apply(\n",
    "        lambda x: nearest_points(x.geometry, x.polygeom)[1] if (x.polygeom is not None and x.distance is not None) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Snap points to nearest point on polygon if applicable\n",
    "    sj[\"geometry\"] = sj.apply(\n",
    "        lambda x: snap(x.geometry, x.nearestpoint, snapdist) if x.nearestpoint is not None else x.geometry,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return sj\n",
    "\n",
    "def sjoin_nearest_replace_geom(left_gdf, right_gdf, **kwargs):\n",
    "    \"\"\"\n",
    "    Performs a spatial join (nearest) and replaces the geometry of left_gdf \n",
    "    with the geometry of right_gdf while retaining left_gdf attributes \n",
    "    and carrying over the 'epointID' column from right_gdf.\n",
    "\n",
    "    Parameters:\n",
    "    - left_gdf (GeoDataFrame): The GeoDataFrame with attributes to keep.\n",
    "    - right_gdf (GeoDataFrame): The GeoDataFrame whose geometry will replace the left_gdf geometry.\n",
    "    - **kwargs: Additional arguments for gpd.sjoin_nearest (e.g., max_distance).\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame: Resulting GeoDataFrame with left_gdf attributes, right_gdf geometry, and epointID.\n",
    "    \"\"\"\n",
    "    # Perform spatial join (nearest)\n",
    "    joined = gpd.sjoin_nearest(left_gdf, right_gdf, how=\"left\", **kwargs)\n",
    "\n",
    "    # Ensure 'geometry_right' exists (GeoPandas renames conflicting geometry columns)\n",
    "    if \"geometry_right\" not in joined.columns:\n",
    "        joined = joined.rename(columns={\"geometry\": \"geometry_right\"})\n",
    "\n",
    "    # Replace the left geometry with the nearest right geometry\n",
    "    joined[\"geometry\"] = joined[\"geometry_right\"]\n",
    "\n",
    "    # Keep original left_gdf columns + 'epointID' from right_gdf\n",
    "    cols_to_keep = list(left_gdf.columns) + [\"epointID\"]\n",
    "    joined = joined[cols_to_keep]\n",
    "\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541cc01b-c383-4108-93a0-9f829e7373ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join ramps to water to get waterbodyID\n",
    "ramps = gpd.read_file(my_path + 'Boatramps_United_States_final_20230104.shp').set_crs(3857, allow_override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4448b78-5c92-4aad-9cb8-79e87527deb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leif.howard\\AppData\\Local\\anaconda3\\envs\\masters\\Lib\\site-packages\\geopandas\\geodataframe.py:1525: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "my_ramps = ramps.loc[ramps['State'] == state_name]\n",
    "ramp_geo = my_ramps[['geometry']]\n",
    "ramp_geo['ramp_ID'] = range(1, len(ramp_geo) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3050b20b-9313-4962-b832-ff76e6a10354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import buffered water\n",
    "buffered_water = gpd.read_file(my_path + my_training_state + \"_buffered_water.shp\").set_crs(3857, allow_override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89e2d21-ecf3-4bd2-8a07-8af0c89075b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get locations of your AIS.  \n",
    "#If your AIS is not present in your state of interest you could identify the points where the road layer intersects your state border and use those\n",
    "pos_data = nas_api_call(my_nas_id, my_training_state)\n",
    "my_data = pos_data[[\"decimalLatitude\", \"decimalLongitude\"]]\n",
    "pos_data_gdf = gpd.GeoDataFrame(\n",
    "    my_data, geometry=gpd.points_from_xy(my_data.decimalLongitude, my_data.decimalLatitude)).dropna().set_crs(3857)#.to_crs(5070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e630d5-1d69-4b38-8a7f-5cbedbcca7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify positive and negative water\n",
    "pos_water_check = buffered_water.sjoin(pos_data_gdf, how=\"left\", predicate=\"contains\")\n",
    "pos_water_check = pos_water_check.drop_duplicates(subset=\"waterID\", keep=\"first\")\n",
    "neg_water = pos_water_check[pos_water_check['index_right'].isna()].drop(columns=[\"index_right\", \"decimalLatitude\", \"decimalLongitude\"], errors=\"ignore\")\n",
    "pos_water = pos_water_check.dropna(subset=[\"index_right\"]).drop(columns=[\"index_right\", \"decimalLatitude\", \"decimalLongitude\"], errors=\"ignore\")\n",
    "pos_water[\"Present\"], neg_water[\"Present\"] = 1.0, 0.0\n",
    "water_w_present = pd.concat([pos_water, neg_water])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b97ac2f8-4ed0-4f6a-abf2-fea3945ea7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify ramps that are within waterbodies and snap unjoinable ramps to the nearest waterbody within maximum distance.\n",
    "ramps_in_water = ramp_geo.sjoin(water_w_present, how=\"left\", predicate=\"within\")\n",
    "ramps_not_in_water = ramps_in_water[ramps_in_water['index_right'].isna()].drop(columns=[\"index_right\"], errors=\"ignore\").copy()\n",
    "ramps_in_water = ramps_in_water.dropna(subset=[\"index_right\"]).drop(columns=[\"index_right\"], errors=\"ignore\").set_crs(3857, allow_override = True)\n",
    "ramps_in_water[\"waterID\"] = ramps_in_water[\"waterID\"].astype(\"int64\")\n",
    "snapped_ramps = snap_points_to_nearest_poly(water_w_present, ramps_not_in_water, 1000)\n",
    "ramps_to_add = snapped_ramps[['ramp_ID', 'waterID_right', 'nearestpoint']].rename(columns={'waterID_right': 'waterID', 'nearestpoint': 'geometry'}).set_crs(3857, allow_override = True)\n",
    "my_ramps = pd.concat([ramps_in_water, ramps_to_add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747637de-0bc1-444a-b556-919804c247e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify water without ramps; identify point on polygon perimeter closest to a road endpoint\n",
    "water_w_ramps_list = my_ramps['waterID'].tolist()\n",
    "water_no_ramps = water_w_present[~water_w_present['waterID'].isin(water_w_ramps_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06a765d-fc89-4229-ac43-960238d05e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify road endpoints; remove duplicates\n",
    "my_roads = gpd.read_file(my_path + 'tl_2022_27_prisecroads.shp').set_crs(5070, allow_override = True)\n",
    "# Extract endpoints for all lines\n",
    "endpoints = my_roads['geometry'].apply(get_endpoints).explode()\n",
    "\n",
    "# Convert the list of endpoints to a DataFrame\n",
    "endpoints_df = pd.DataFrame(endpoints.tolist(), columns=['x', 'y'])\n",
    "\n",
    "# Remove duplicate points\n",
    "endpoints_df = endpoints_df.drop_duplicates()\n",
    "\n",
    "# Optionally, you can create a GeoDataFrame for the endpoints\n",
    "endpoints_gdf = gpd.GeoDataFrame(endpoints_df, geometry=gpd.points_from_xy(endpoints_df['x'], endpoints_df['y'])).set_crs(3857, allow_override = True).drop(columns = ['x', 'y'])\n",
    "endpoints_gdf['epointID'] = range(1, len(endpoints_gdf) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39db516a-390e-46f3-b793-eac44b9eb4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ramps_in_water_sj = sjoin_nearest_replace_geom(my_ramps, endpoints_gdf)\n",
    "lakes_no_ramp_sj = sjoin_nearest_replace_geom(water_no_ramps, endpoints_gdf)\n",
    "my_endpoints = pd.concat([ramps_in_water_sj, lakes_no_ramp_sj])\n",
    "pos_endpoints = my_endpoints.loc[my_endpoints['Present'] == 1.0]\n",
    "neg_endpoints = my_endpoints.loc[my_endpoints['Present'] == 0.0]\n",
    "joined = gpd.sjoin_nearest(neg_endpoints, pos_endpoints, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7d265-f529-4942-93cf-0a847f38f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate road distance\n",
    "source_gdf = neg_endpoints.set_crs(3857, allow_override = True)\n",
    "target_gdf = pos_endpoints.set_crs(3857, allow_override = True)\n",
    "network_gdf = my_roads.set_crs(3857, allow_override = True)\n",
    "\n",
    "# Ensure all GeoDataFrames use the same CRS\n",
    "if not (source_gdf.crs == target_gdf.crs == network_gdf.crs):\n",
    "    target_gdf = target_gdf.to_crs(source_gdf.crs)\n",
    "    network_gdf = network_gdf.to_crs(source_gdf.crs)\n",
    "\n",
    "# Build a graph from the polyline network\n",
    "def build_network(gdf):\n",
    "    G = nx.Graph()\n",
    "    for _, row in gdf.iterrows():\n",
    "        line = row.geometry\n",
    "        if isinstance(line, LineString):\n",
    "            coords = list(line.coords)\n",
    "            for i in range(len(coords) - 1):\n",
    "                G.add_edge(\n",
    "                    coords[i],\n",
    "                    coords[i + 1],\n",
    "                    weight=Point(coords[i]).distance(Point(coords[i + 1]))\n",
    "                )\n",
    "    return G\n",
    "\n",
    "network_graph = build_network(network_gdf)\n",
    "\n",
    "# Helper function to find the nearest node in the network to a given point\n",
    "def find_nearest_node(graph, point):\n",
    "    nodes = list(graph.nodes)\n",
    "    distances = [Point(node).distance(point) for node in nodes]\n",
    "    return nodes[distances.index(min(distances))]\n",
    "\n",
    "# Calculate shortest distances for an array of precomputed nearest neighbor pairs\n",
    "def calculate_shortest_distances_with_pairs(point_pairs, source_gdf, target_gdf, network_graph):\n",
    "    results = []\n",
    "    \n",
    "    for pair in point_pairs:\n",
    "        source_id, target_id = pair\n",
    "        # Get the source and target geometries\n",
    "        source_row = source_gdf[source_gdf[\"epointID\"] == source_id].iloc[0]\n",
    "        target_row = target_gdf[target_gdf[\"epointID\"] == target_id].iloc[0]\n",
    "        \n",
    "        source_geom = source_row.geometry\n",
    "        target_geom = target_row.geometry\n",
    "        \n",
    "        # Find nearest network nodes for source and target\n",
    "        source_node = find_nearest_node(network_graph, source_geom)\n",
    "        target_node = find_nearest_node(network_graph, target_geom)\n",
    "        \n",
    "        # Compute the shortest path distance along the network\n",
    "        try:\n",
    "            path_length = nx.shortest_path_length(\n",
    "                network_graph, source_node, target_node, weight=\"weight\"\n",
    "            )\n",
    "        except nx.NetworkXNoPath:\n",
    "            path_length = float(\"inf\")  # No path found\n",
    "        \n",
    "        # Record the result\n",
    "        results.append({\n",
    "            \"source_point_id\": source_id,\n",
    "            \"target_point_id\": target_id,\n",
    "            \"network_distance\": path_length\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "point_pairs = joined[['epointID_left', 'epointID_right']].to_numpy()\n",
    "#point_pairs = point_pairs[:5] # Test with subset first\n",
    "# Calculate distances for the point pairs\n",
    "shortest_distances = calculate_shortest_distances_with_pairs(point_pairs, source_gdf, target_gdf, network_graph)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(shortest_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0402942f-d79b-449c-ab9e-6f0e9f6c7b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_point_id</th>\n",
       "      <th>target_point_id</th>\n",
       "      <th>network_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1122</td>\n",
       "      <td>1122</td>\n",
       "      <td>0.073961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4002</td>\n",
       "      <td>4002</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4002</td>\n",
       "      <td>4002</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3006</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.102876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3717</td>\n",
       "      <td>3717</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_point_id  target_point_id  network_distance\n",
       "0             1122             1122          0.073961\n",
       "1             4002             4002          0.001037\n",
       "2             4002             4002          0.001037\n",
       "3             3006             3001          0.102876\n",
       "4             3717             3717          0.009600"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38662905-3f5f-40dc-9877-89a786fed921",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('road_distance_dres_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28a78f-28b9-4698-96db-9cf0950d4daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
