{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a035f18-d381-4e93-9c00-becab59a2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.ops import nearest_points\n",
    "import networkx as nx\n",
    "from shapely.geometry import Point, MultiPoint, LineString, MultiLineString, GeometryCollection\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import io\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.ops import snap, nearest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b4480-9dc2-4218-93e6-4465aa4379ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "my_training_state = 'MT' # State USPS abbreviation\n",
    "state_name = 'Montana'\n",
    "my_nas_id = 5\n",
    "# IA = 19; ID = 16; IL = 17; MN = 27; MO = 29; MT = 30; OR = 41;  WA = 53; WI = 55\n",
    "state_fips = '30' # Replace last 2 digits with your state's FIP code\n",
    "my_path = 'data/' + my_training_state + '/' # leave this alone   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d38d9-e447-445c-ad43-247f4e4cde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download road shapefile\n",
    "road_url = f'https://www2.census.gov/geo/tiger/TIGER2022/PRISECROADS/tl_2022_{state_fips}_prisecroads.zip'\n",
    "local_path = my_path\n",
    "print('Downloading shapefile...')\n",
    "r = requests.get(road_url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "print(\"Done\")\n",
    "z.extractall(path=local_path) # extract to folder\n",
    "filenames = [y for y in sorted(z.namelist()) for ending in ['dbf', 'prj', 'shp', 'shx'] if y.endswith(ending)] \n",
    "print(filenames)\n",
    "#Download USGS boat access data \n",
    "# URL of the compressed file containing multiple files\n",
    "URL_BASE = \"https://www.sciencebase.gov/catalog/file/get/63b81b50d34e92aad3cc004d?facet=Boatramps_United_States_final_20230104\"\n",
    "\n",
    "# Define the desired extensions\n",
    "desired_extensions = ['.dbf', '.prj', '.shp', '.shx']\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(URL_BASE)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Save the content to a temporary location (e.g., in memory)\n",
    "    zip_file = BytesIO(response.content)\n",
    "\n",
    "    # Extract the ZIP file contents to a folder\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        # Create a directory to store the extracted files\n",
    "        os.makedirs(my_path, exist_ok=True)\n",
    "        \n",
    "        # Loop through the files in the zip and extract only the desired ones\n",
    "        for file_name in zip_ref.namelist():\n",
    "            if any(file_name.endswith(ext) for ext in desired_extensions):\n",
    "                # Extract the file\n",
    "                zip_ref.extract(file_name, my_path)\n",
    "                print(f\"Extracted: {file_name}\")\n",
    "\n",
    "    print(\"Files extracted successfully to my_path directory.\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c1435-1326-4327-ab81-69ffe6664da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nas_api_call(nas_id):\n",
    "    URL_BASE = 'http://nas.er.usgs.gov/api/v2/'\n",
    "    url_request = f\"{URL_BASE}/occurrence/search?species_ID={nas_id}\"\n",
    "    response = requests.get(url_request, timeout=None).json()\n",
    "    results = pd.json_normalize(response, 'results')\n",
    "    return results\n",
    "\n",
    "def get_intersection_points(line_gdf, polygon_gdf):\n",
    "    \"\"\"\n",
    "    Returns a GeoDataFrame with intersection points between a line and a polygon.\n",
    "    \n",
    "    Parameters:\n",
    "    - line_gdf (GeoDataFrame): A GeoDataFrame containing LineString geometries.\n",
    "    - polygon_gdf (GeoDataFrame): A GeoDataFrame containing Polygon geometries.\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame: A GeoDataFrame containing the intersection points as Point geometries.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure CRS match\n",
    "    if line_gdf.crs != polygon_gdf.crs:\n",
    "        polygon_gdf = polygon_gdf.to_crs(line_gdf.crs)\n",
    "\n",
    "    # Compute intersection\n",
    "    intersection = line_gdf.unary_union.intersection(polygon_gdf.unary_union)\n",
    "\n",
    "    # Extract intersection points\n",
    "    points = []\n",
    "\n",
    "    def extract_points(geom):\n",
    "        \"\"\" Recursively extract points from geometry objects. \"\"\"\n",
    "        if geom.is_empty:\n",
    "            return\n",
    "        if isinstance(geom, Point):\n",
    "            points.append(geom)\n",
    "        elif isinstance(geom, MultiPoint):\n",
    "            points.extend(geom.geoms)\n",
    "        elif isinstance(geom, (LineString, MultiLineString)):\n",
    "            points.extend(Point(coord) for coord in geom.coords)\n",
    "        elif isinstance(geom, GeometryCollection):\n",
    "            for sub_geom in geom.geoms:\n",
    "                extract_points(sub_geom)\n",
    "\n",
    "    extract_points(intersection)\n",
    "\n",
    "    # Create and return a GeoDataFrame of points\n",
    "    return gpd.GeoDataFrame(geometry=points, crs=line_gdf.crs) if points else gpd.GeoDataFrame(columns=['geometry'], crs=line_gdf.crs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to get the endpoints of a line geometry\n",
    "def get_endpoints(geometry):\n",
    "    # Ensure the geometry is a LineString\n",
    "    if geometry.geom_type == 'LineString':\n",
    "        # Get the first and last coordinate of the line\n",
    "        return [geometry.coords[0], geometry.coords[-1]]\n",
    "    return []\n",
    "\n",
    "def snap_points_to_nearest_poly(poly: gpd.GeoDataFrame, point: gpd.GeoDataFrame, snapdist: float) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Snaps points to the nearest polygon within a given distance.\n",
    "    \n",
    "    Parameters:\n",
    "        poly (GeoDataFrame): GeoDataFrame containing polygon geometries.\n",
    "        point (GeoDataFrame): GeoDataFrame containing point geometries.\n",
    "        snapdist (float): Maximum search distance to find the nearest polygon.\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: Updated point GeoDataFrame with snapped geometries.\n",
    "    \"\"\"\n",
    "    # Ensure both datasets use the same projected CRS (Sweden EPSG:3006 in original, changed to 26915)\n",
    "    poly = poly.to_crs(3857)\n",
    "    point = point.set_crs(3857)\n",
    "    \n",
    "    # Create unique IDs\n",
    "    poly[\"polyid\"] = range(poly.shape[0])\n",
    "    point[\"pointid\"] = range(point.shape[0])\n",
    "    \n",
    "    # Store original polygon geometry\n",
    "    poly[\"polygeom\"] = poly.geometry\n",
    "    \n",
    "    # Perform spatial join to find nearest polygons within snap distance\n",
    "    sj = gpd.sjoin_nearest(left_df=point, right_df=poly, how=\"left\", max_distance=snapdist)\n",
    "    \n",
    "    # Measure distances (set to None if no polygon within snapdistance)\n",
    "    sj[\"distance\"] = sj.apply(lambda x: x.geometry.distance(x.polygeom) if x.polygeom is not None else None, axis=1)\n",
    "    \n",
    "    # Sort by distance and drop duplicates (keeping closest polygon match)\n",
    "    sj = sj.sort_values(by=[\"pointid\", \"distance\"], ascending=True, na_position=\"last\")\n",
    "    sj = sj.drop_duplicates(subset=\"pointid\", keep=\"first\")\n",
    "    \n",
    "    # Find the nearest point on the polygon\n",
    "    sj[\"nearestpoint\"] = sj.apply(\n",
    "        lambda x: nearest_points(x.geometry, x.polygeom)[1] if (x.polygeom is not None and x.distance is not None) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Snap points to nearest point on polygon if applicable\n",
    "    sj[\"geometry\"] = sj.apply(\n",
    "        lambda x: snap(x.geometry, x.nearestpoint, snapdist) if x.nearestpoint is not None else x.geometry,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return sj\n",
    "\n",
    "def sjoin_nearest_replace_geom(left_gdf, right_gdf, **kwargs):\n",
    "    \"\"\"\n",
    "    Performs a spatial join (nearest) and replaces the geometry of left_gdf \n",
    "    with the geometry of right_gdf while retaining left_gdf attributes \n",
    "    and carrying over the 'epointID' column from right_gdf.\n",
    "\n",
    "    Parameters:\n",
    "    - left_gdf (GeoDataFrame): The GeoDataFrame with attributes to keep.\n",
    "    - right_gdf (GeoDataFrame): The GeoDataFrame whose geometry will replace the left_gdf geometry.\n",
    "    - **kwargs: Additional arguments for gpd.sjoin_nearest (e.g., max_distance).\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame: Resulting GeoDataFrame with left_gdf attributes, right_gdf geometry, and epointID.\n",
    "    \"\"\"\n",
    "    # Perform spatial join (nearest)\n",
    "    joined = gpd.sjoin_nearest(left_gdf, right_gdf, how=\"left\", **kwargs)\n",
    "\n",
    "    # Ensure 'geometry_right' exists (GeoPandas renames conflicting geometry columns)\n",
    "    if \"geometry_right\" not in joined.columns:\n",
    "        joined = joined.rename(columns={\"geometry\": \"geometry_right\"})\n",
    "\n",
    "    # Replace the left geometry with the nearest right geometry\n",
    "    joined[\"geometry\"] = joined[\"geometry_right\"]\n",
    "\n",
    "    # Keep original left_gdf columns + 'epointID' from right_gdf\n",
    "    cols_to_keep = list(left_gdf.columns) + [\"epointID\"]\n",
    "    joined = joined[cols_to_keep]\n",
    "\n",
    "    return joined\n",
    "\n",
    "def get_boundary_intersection_points(line_gdf, polygon_gdf):\n",
    "    \"\"\"\n",
    "    Returns a GeoDataFrame with intersection points where a line intersects the boundary of a polygon.\n",
    "\n",
    "    Parameters:\n",
    "    - line_gdf (GeoDataFrame): A GeoDataFrame containing LineString geometries.\n",
    "    - polygon_gdf (GeoDataFrame): A GeoDataFrame containing Polygon geometries.\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame: A GeoDataFrame containing the intersection points as Point geometries.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure CRS match\n",
    "    if line_gdf.crs != polygon_gdf.crs:\n",
    "        polygon_gdf = polygon_gdf.to_crs(line_gdf.crs)\n",
    "\n",
    "    # Extract only the polygon boundaries (exterior rings)\n",
    "    polygon_boundaries = polygon_gdf.boundary\n",
    "\n",
    "    # Compute intersection between roads and polygon boundaries\n",
    "    intersection = line_gdf.unary_union.intersection(polygon_boundaries.unary_union)\n",
    "\n",
    "    # Extract intersection points\n",
    "    points = []\n",
    "\n",
    "    def extract_points(geom):\n",
    "        \"\"\" Recursively extract points from geometry objects. \"\"\"\n",
    "        if geom.is_empty:\n",
    "            return\n",
    "        if isinstance(geom, Point):\n",
    "            points.append(geom)\n",
    "        elif isinstance(geom, MultiPoint):\n",
    "            points.extend(geom.geoms)\n",
    "        elif isinstance(geom, (LineString, MultiLineString)):\n",
    "            points.extend(Point(coord) for coord in geom.coords)\n",
    "        elif isinstance(geom, GeometryCollection):\n",
    "            for sub_geom in geom.geoms:\n",
    "                extract_points(sub_geom)\n",
    "\n",
    "    extract_points(intersection)\n",
    "\n",
    "    # Create and return a GeoDataFrame of points\n",
    "    return gpd.GeoDataFrame(geometry=points, crs=line_gdf.crs) if points else gpd.GeoDataFrame(columns=['geometry'], crs=line_gdf.crs)\n",
    "\n",
    "# Define a function to compute the nearest distance for each point in gdf1\n",
    "def nearest_distance(row, gdf2):\n",
    "    # Find the nearest point in gdf2\n",
    "    nearest_geom = nearest_points(row.geometry, gdf2.unary_union)[1]\n",
    "    # Return the distance to the nearest point\n",
    "    return row.geometry.distance(nearest_geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e2d21-ecf3-4bd2-8a07-8af0c89075b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get locations of your AIS.  \n",
    "#If your AIS is not present in your state of interest you could identify the points where the road layer intersects your state border and use those\n",
    "pos_data = nas_api_call(my_nas_id)\n",
    "my_data = pos_data[[\"decimalLatitude\", \"decimalLongitude\"]]\n",
    "pos_data_gdf = gpd.GeoDataFrame(\n",
    "    my_data, geometry=gpd.points_from_xy(my_data.decimalLongitude, my_data.decimalLatitude)).dropna().set_crs(3857)#.to_crs(5070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1154b4e-776e-42a7-9280-854f8bc5f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get points where roads intersect your state boundary\n",
    "my_roads = gpd.read_file(my_path + 'tl_2022_' + state_fips + '_prisecroads.shp').set_crs(3857, allow_override = True)\n",
    "state_boundary = gpd.read_file(my_path + 'tl_2012_us_state.shp').set_crs(3857, allow_override = True)\n",
    "my_boundary = state_boundary[state_boundary['STUSPS'] == my_training_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7c828-eac8-4ff6-8c0d-12cdfc79bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_points_gdf = get_boundary_intersection_points(my_roads, my_boundary)\n",
    "intersection_points_gdf['intID'] = range(1, len(intersection_points_gdf) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b5672-c114-4208-959e-bb9bd33e2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row in gdf1\n",
    "intersection_points_gdf['distance_to_nearest'] = intersection_points_gdf.apply(nearest_distance, axis=1, gdf2=pos_data_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e9d14-30af-40ee-bfe0-dfe24c70de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot to spot check your files so far\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# Plot the boundary\n",
    "my_boundary.plot(ax=ax, edgecolor='red', facecolor='none', linewidth=2, label=\"State Boundary\")\n",
    "# Plot the roads\n",
    "my_roads.plot(ax=ax, color='blue', linewidth=1, label=\"Roads\")\n",
    "\n",
    "intersection_points_gdf.plot(ax=ax, color='yellow', label=\"Intersections\")\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Roads and State Boundary\", fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06a765d-fc89-4229-ac43-960238d05e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify road endpoints; remove duplicates\n",
    "# Extract endpoints for all lines\n",
    "endpoints = my_roads['geometry'].apply(get_endpoints).explode()\n",
    "# Convert the list of endpoints to a DataFrame\n",
    "endpoints_df = pd.DataFrame(endpoints.tolist(), columns=['x', 'y'])\n",
    "# Remove duplicate points\n",
    "endpoints_df = endpoints_df.drop_duplicates()\n",
    "# Optionally, you can create a GeoDataFrame for the endpoints\n",
    "endpoints_gdf = gpd.GeoDataFrame(endpoints_df, geometry=gpd.points_from_xy(endpoints_df['x'], endpoints_df['y'])).set_crs(3857, allow_override = True).drop(columns = ['x', 'y'])\n",
    "endpoints_gdf['epointID'] = range(1, len(endpoints_gdf) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d16c6-2e88-476d-94ae-fc319b90550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import buffered water\n",
    "buffered_water = gpd.read_file(my_path + my_training_state + \"_buffered_water.shp\").set_crs(3857, allow_override = True)\n",
    "# Join ramps to water to get waterbodyID\n",
    "buffered_water[\"Present\"] = 0.0\n",
    "buffered_water['waterID'] = range(1, len(buffered_water) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4448b78-5c92-4aad-9cb8-79e87527deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ramps = gpd.read_file(my_path + 'Boatramps_United_States_final_20230104.shp').set_crs(3857, allow_override=True)\n",
    "my_ramps = ramps.loc[ramps['State'] == state_name]\n",
    "ramp_geo = my_ramps[['geometry']]\n",
    "ramp_geo['rampID'] = range(1, len(ramp_geo) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ac2f8-4ed0-4f6a-abf2-fea3945ea7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify ramps that are within waterbodies and snap unjoinable ramps to the nearest waterbody within maximum distance.\n",
    "ramps_in_water = ramp_geo.sjoin(buffered_water, how=\"left\", predicate=\"within\")\n",
    "ramps_not_in_water = ramps_in_water[ramps_in_water['index_right'].isna()].drop(columns=[\"index_right\"], errors=\"ignore\").copy()\n",
    "ramps_in_water = ramps_in_water.dropna(subset=[\"index_right\"]).drop(columns=[\"index_right\"], errors=\"ignore\").set_crs(3857, allow_override = True)\n",
    "ramps_in_water[\"waterID\"] = ramps_in_water[\"waterID\"].astype(\"int64\")\n",
    "snapped_ramps = snap_points_to_nearest_poly(buffered_water, ramps_not_in_water, 1000)\n",
    "ramps_to_add = snapped_ramps[['rampID', 'waterID_right', 'nearestpoint']].rename(columns={'waterID_right': 'waterID', 'nearestpoint': 'geometry'}).set_crs(3857, allow_override = True)\n",
    "my_ramps = pd.concat([ramps_in_water, ramps_to_add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747637de-0bc1-444a-b556-919804c247e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify water without ramps; identify point on polygon perimeter closest to a road endpoint\n",
    "water_w_ramps_list = my_ramps['waterID'].tolist()\n",
    "water_no_ramps = buffered_water[~buffered_water['waterID'].isin(water_w_ramps_list)]\n",
    "ramps_in_water_sj = sjoin_nearest_replace_geom(my_ramps, endpoints_gdf)\n",
    "lakes_no_ramp_sj = sjoin_nearest_replace_geom(water_no_ramps, endpoints_gdf)\n",
    "my_endpoints = pd.concat([ramps_in_water_sj, lakes_no_ramp_sj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23aef2-13f0-4d3f-abf7-a5d2a9955860",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = gpd.sjoin_nearest(my_endpoints, intersection_points_gdf, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7d265-f529-4942-93cf-0a847f38f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate road distance\n",
    "source_gdf = my_endpoints.set_crs(3857, allow_override = True)\n",
    "target_gdf = intersection_points_gdf.set_crs(3857, allow_override = True)\n",
    "network_gdf = my_roads.set_crs(3857, allow_override = True)\n",
    "\n",
    "# Ensure all GeoDataFrames use the same CRS\n",
    "if not (source_gdf.crs == target_gdf.crs == network_gdf.crs):\n",
    "    target_gdf = target_gdf.to_crs(source_gdf.crs)\n",
    "    network_gdf = network_gdf.to_crs(source_gdf.crs)\n",
    "\n",
    "# Build a graph from the polyline network\n",
    "def build_network(gdf):\n",
    "    G = nx.Graph()\n",
    "    for _, row in gdf.iterrows():\n",
    "        line = row.geometry\n",
    "        if isinstance(line, LineString):\n",
    "            coords = list(line.coords)\n",
    "            for i in range(len(coords) - 1):\n",
    "                G.add_edge(\n",
    "                    coords[i],\n",
    "                    coords[i + 1],\n",
    "                    weight=Point(coords[i]).distance(Point(coords[i + 1]))\n",
    "                )\n",
    "    return G\n",
    "\n",
    "network_graph = build_network(network_gdf)\n",
    "\n",
    "# Helper function to find the nearest node in the network to a given point\n",
    "def find_nearest_node(graph, point):\n",
    "    nodes = list(graph.nodes)\n",
    "    distances = [Point(node).distance(point) for node in nodes]\n",
    "    return nodes[distances.index(min(distances))]\n",
    "\n",
    "# Calculate shortest distances for an array of precomputed nearest neighbor pairs\n",
    "def calculate_shortest_distances_with_pairs(point_pairs, source_gdf, target_gdf, network_graph):\n",
    "    results = []\n",
    "    \n",
    "    for pair in point_pairs:\n",
    "        source_id, target_id = pair\n",
    "        # Get the source and target geometries\n",
    "        source_row = source_gdf[source_gdf[\"epointID\"] == source_id].iloc[0]\n",
    "        target_row = target_gdf[target_gdf[\"intID\"] == target_id].iloc[0]\n",
    "        \n",
    "        source_geom = source_row.geometry\n",
    "        target_geom = target_row.geometry\n",
    "        \n",
    "        # Find nearest network nodes for source and target\n",
    "        source_node = find_nearest_node(network_graph, source_geom)\n",
    "        target_node = find_nearest_node(network_graph, target_geom)\n",
    "        \n",
    "        # Compute the shortest path distance along the network\n",
    "        try:\n",
    "            path_length = nx.shortest_path_length(\n",
    "                network_graph, source_node, target_node, weight=\"weight\"\n",
    "            )\n",
    "        except nx.NetworkXNoPath:\n",
    "            path_length = float(\"inf\")  # No path found\n",
    "        \n",
    "        # Record the result\n",
    "        results.append({\n",
    "            \"epointID\": source_id,\n",
    "            \"intID\": target_id,\n",
    "            \"network_distance\": path_length\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "point_pairs = joined[['epointID', 'intID']].to_numpy()\n",
    "#point_pairs = point_pairs[:5] # Test with subset first\n",
    "# Calculate distances for the point pairs\n",
    "shortest_distances = calculate_shortest_distances_with_pairs(point_pairs, source_gdf, target_gdf, network_graph)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(shortest_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f742b29-f808-4fb4-b4c3-584792517bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df = pd.merge(results_df, intersection_points_gdf, on = 'intID', how = 'left')\n",
    "dist_df['total_dist_roads'] = dist_df['network_distance'] + dist_df['distance_to_nearest']\n",
    "ramps_w_dist = pd.merge(ramps_in_water_sj, dist_df, on = 'epointID', how = 'left')\n",
    "lakes_no_ramp_w_dist = pd.merge(lakes_no_ramp_sj, dist_df, on = 'epointID', how = 'left')\n",
    "final_dist_df = pd.concat([ramps_w_dist, lakes_no_ramp_w_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf4004-eec5-4190-87cc-b70c6f9d0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify shortest distance by waterID\n",
    "min_dist_to_source = final_dist_df.loc[final_dist_df.groupby(\"waterID\")[\"total_dist\"].idxmin()]\n",
    "# Join back to waterbody shapefile and convert to raster\n",
    "water_w_dist = pd.merge(buffered_water, min_dist_to_source, on = 'waterID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308558f4-2574-4f11-bcab-c7fa23e8a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_road_dist(joined_gdf: gpd.GeoDataFrame, resolution: int = 1000):\n",
    "    bounds = joined_gdf.total_bounds\n",
    "    transform = rasterio.transform.from_origin(bounds[0], bounds[3], resolution, resolution)\n",
    "    out_shape = (\n",
    "        int(np.ceil((bounds[3] - bounds[1]) / resolution)),  \n",
    "        int(np.ceil((bounds[2] - bounds[0]) / resolution))\n",
    "    )\n",
    "    \n",
    "    column_name = \"dist_roads\"  # Change this to dynamically select the column if needed\n",
    "    raster = rasterize(\n",
    "        [(geom, value) for geom, value in zip(joined_gdf.geometry, joined_gdf[column_name])],\n",
    "        out_shape=out_shape,\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        dtype=rasterio.float32\n",
    "    )\n",
    "    \n",
    "    output_filename = f\"{my_path}{my_training_state}_{column_name}_unifested.tif\"\n",
    "    \n",
    "    with rasterio.open(\n",
    "        output_filename, \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=out_shape[0],\n",
    "        width=out_shape[1],\n",
    "        count=1,\n",
    "        dtype=rasterio.float32,\n",
    "        crs=my_crs,\n",
    "        transform=transform\n",
    "    ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "        dst.set_band_description(1, column_name)  # Set band name\n",
    "    \n",
    "    # Plot the raster\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(raster, cmap='viridis', extent=[bounds[0], bounds[2], bounds[1], bounds[3]])\n",
    "    plt.colorbar(label=f'{column_name} Richness')\n",
    "    plt.title('Rasterized GeoDataFrame')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f4733-e18b-476b-b036-85259555dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_road_dist(water_w_dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
